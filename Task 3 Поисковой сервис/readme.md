# Домашнее задание №3: Поисковый сервис

## Задание такое:

Требуется реализовать HTTP-сервер для поиска пользователей в XML-датасете с поддержкой фильтрации, сортировки и пагинации. Проект состоит из двух компонентов:

### Структура файлов

```
vklec3/
├── client.go          # Клиент поискового сервиса (готовый код)
├── server.go          # HTTP-обработчик поискового сервиса (реализован в рамках задания)
├── server_test.go     # Тесты SearchServer
├── client_test.go     # Тесты SearchClient
├── cover              # Пример файла для оценки покрытия
├── cover.html         # Визуализация файла cover
├── dataset.xml        # Датасет с пользователями
└── readme.md
```

### Компоненты системы

1. **SearchClient** (`client.go`) - структура с методом `FindUsers`, который отправляет запрос во внешнюю систему и возвращает результат, немного преобразуя его. Код уже был написан, требовалось ≥90% покрытия метода `FindUsers`

2. **SearchServer** (`server.go`) - `SearchServer` - своего рода внешняя система. Непосредственно занимается поиском данных в файле dataset.xml. В продакшене бы запускалась в виде отдельного веб-сервиса. Код необходимо написать вам. Требует реализации и тестового покрытия ≥90%.

### Требования к функциональности

#### Параметры запроса

- **`query`** - строка поиска по полям `Name` (first_name + last_name) и `About`
- **`order_field`** - поле сортировки (`Id`, `Age`, `Name`). При пустом значении сортирует по `Name` по умолчанию. Для некорректного значения сервер возвращает JSON-ошибку.
- **`order_by`** - направление сортировки (1 = возрастание, -1 = убывание, 0 = без сортировки)
- **`offset`** - смещение в результатах (количество записей для пропуска)
- **`limit`** - максимальное количество возвращаемых записей

#### Поведение сервера

- Фильтрация по `query` осуществляется по полям `Name` и `About`
- При сортировке (`order_by ≠ 0`) результаты сортируются, затем применяется пагинация
- Для некорректного `order_field` сервер возвращает HTTP 400 с JSON-ответом: `{"Error": "OrderField invalid"}`
- Файл `dataset.xml` содержит структуру с полями: `id`, `first_name`, `last_name`, `age`, `about`, `gender`

#### Пример запроса и результата

Запрос: `order_by=-1&order_field=age&limit=1&offset=0&query=on`

Возвращает одного пользователя с максимальным возрастом из тех, у кого в поле `Name` или `About` присутствует строка "on".

---

## Реализация

### **Парсинг XML с потоковой обработкой**

Для оптимизации при работе с большими файлами (потенциально 10GB+) реализована потоковая обработка XML вместо загрузки всего файла в память. Если бы мы делали полный **Unmarshal** файла, могло бы не хватить оперативки, так что делаем так:

```go
dec := xml.NewDecoder(f)
for {
    tok, err := dec.Token()
    if err != nil { break }
    if start, ok := tok.(xml.StartElement); ok && start.Name.Local == "row" {
        var xr xmlRow
        dec.DecodeElement(&xr, &start)
        // обработка элемента
    }
}
```

Благодаря этому элементы `<row>` декодируются по одному, не загружая весь файл в памяти. Применение `offset` и `limit` во время обработки при отсутствии сортировки позволяет прерывать чтение после накопления необходимого количества записей. Я использую `goto RESPOND` для ранного выхода из цикла, когда достигнут лимит, чтобы не добавлять флаг и двойную проверку для выхода из цикла.

### **Обработка данных**

Последовательность обработки может отличаться в зависимости от того, какой запрос требуется.
- **Без сортировки** (`order_by == 0`): фильтрация -> пагинация -> прерывание чтения
- **С сортировкой** (`order_by != 0`): фильтрация всех записей -> сортировка -> пагинация

Это гарантирует корректное смещение при сортировке, так как сет результата для пагинации формируется после сортировки.

Пример:
Данные: 
`[Zebra, Apple, Banana, Cat, Dog, Elephant]`

`offset=0`, `limit=3`, сортировка по алфавиту

Правильно, пагинация ПОСЛЕ сортировки:
1. Берем все: `[Zebra, Apple, Banana, Cat, Dog, Elephant]`
2. Сортируем: `[Apple, Banana, Cat, Dog, Elephant, Zebra]`
3. Пагинируем (0,3): `[Apple, Banana, Cat]`

Неправильно, пагинация до сортировки:
1. Берем первые 3: `[Zebra, Apple, Banana]`
2. Сортируем: `[Apple, Banana, Zebra]`
3. Пагинируем (0,3): `[Apple, Banana, Zebra]` - можно пропустить `Cat`.

### **Оптимизация конструирования строк**

При создании тестовых XML-данных использован `strings.Builder` вместо конкатенации. Метод позволяет избегат избыточного создания промежуточных строк и новых распределений памяти, улучшая производительность при большом объёме данных.

```go
var builder strings.Builder
builder.WriteString(xml1)
builder.WriteString(xml2)
// ... вместо str = str + xml1 + xml2 + ...
```

### **Сортировка на этапе обработки**

Использован `sort.SliceStable` для стабильной сортировки (гарантирует сохранение порядка равных элементов) по выбранному полю с поддержкой трёх полей (Id, Age, Name) и двух направлений (по возрастанию/убыванию).

```go
type xmlRow struct {
    ID        int    `xml:"id"`
    Age       int    `xml:"age"`
    FirstName string `xml:"first_name"`
    LastName  string `xml:"last_name"`
    About     string `xml:"about"`
    Gender    string `xml:"gender"`
}

type User struct {
    ID     int
    Name   string // first_name + last_name
    Age    int
    About  string
    Gender string
}
```

### Глобальная переменная только для тестирования

```go
var datasetFile = "dataset.xml"
```
---

## Тестирование

### Покрытие компонентов

#### SearchServer (`server.go`)

Тесты покрывают:
- Потоковое чтение и фильтрацию XML
- Валидацию параметров (`limit`, `offset`, `order_by`, `order_field`)
- Сортировку по Id, Age, Name в обоих направлениях
- Пагинацию с различными комбинациями смещения/требуемого количества лимитов
- Поведение при смещении, превышающем длину результатов
- Ошибки открытия файла (HTTP 500)
- JSON-ошибку при некорректном `order_field` (HTTP 400)
- Фильтрацию по `query` в полях Name и About
- Поведение при пустом `order_field` (по умолчанию сортирует по Name)

**Стратегия тестирования:**
- Создание временных XML-файлов `os.CreateTemp` с контролируемыми данными, закрытие через defer
- Использование `httptest.NewRequest` и `httptest.NewRecorder` для написания тестов
- Таблично-ориентированные тесты для параметризации сценариев

#### SearchClient (`client.go`)

Тесты покрывают:
- Успешный запрос с корректным ответом и проверкой пагинации
- HTTP 400 с JSON-ошибкой `ErrorBadOrderField` и маппинг на клиентскую ошибку "OrderFeld %s invalid"
- HTTP 400 с невалидным JSON в теле ошибки
- HTTP 400 с неизвестной ошибкой (не OrderBadFieldError)
- HTTP 401 (неавторизованный доступ)
- HTTP 500 (внутренняя ошибка сервера)
- Timeout при сетевых задержках (использование пользовательского `http.Client` с малым таймаутом)
- Неизвестная сетевая ошибка через `http.RoundTripper`
- NextPage = false при возврате меньшего количества элементов, чем запрошено

**Стратегия тестирования:**
- Использование `httptest.NewServer` для имитации серверных ответов
- Injection кастомного `http.Client` для контроля таймаут и ошибок
- Реализация `http.RoundTripper` для генерации произвольных сетевых ошибок

### Используемые пакеты и инструменты

- `encoding/xml` с Decoder и Token
- `net/http/httptest` (NewRequest, NewRecorder, NewServer)
- `encoding/json` для сериализации/десериализации
- `sort.SliceStable` с замыканиями для гибкого выбора критерия
- `os.CreateTemp`, `os.Remove` для изоляции тестов

В тестах, по требованиям задания, требовалось достигнуть **>90% покрытия** для обоих компонентов (`SearchServer` и `SearchClient`). Чтобы показать покрытие, использовался встроенный инструмент для анализа тестового покрытия. Измерение и анализ покрытия осуществляется следующим образом:

**Сбор данных о покрытии:**
```bash
go test -coverprofile=cover.out ./...
```

Флаг `-coverprofile=cover.out` генерирует файл, в котором записывается информация о покрытии каждого участка кода каждым тестом.

**Генерация HTML-отчёта:**
```bash
go tool cover -html=cover.out -o cover.html
```

Утилита `go tool cover` преобразует профайл покрытия в интерактивный HTML-отчёт. В отчёте показывается визуализация частей кода, которые были покрыты. HTML-файл открывается в браузере и позволяет быстро идентифицировать непокрытые ветви логики.

---

## Установка и запуск

### Требования (для Windows, писалось на Windows)

1. Go 1.11+
2. Выполнить все тесты с выводом информации:

```bash
go test -v
```

3. Запуск тестов с информацией о покрытии:

```bash
go test -cover
```
4. Создать профиль покрытия:

```
go tool cover -html=cover.out -o cover.html
```

5. Сгенерировать HTML-отчёт:

```bash
go tool cover -html=cover.out -o cover.html
```

6. Открыть файл `cover.html` в браузере.



### Примеры использования

#### Прямой запуск сервера с httptest

```go
ts := httptest.NewServer(http.HandlerFunc(SearchServer))
defer ts.Close()

client := &SearchClient{AccessToken: "token", URL: ts.URL}
result, err := client.FindUsers(SearchRequest{
    Limit:      10,
    Offset:     0,
    Query:      "developer",
    OrderField: "Age",
    OrderBy:    1,
})
```
### Поиск первых 10 пользователей без сортировки:
```
GET /search?limit=10&offset=0
```

### Поиск пользователей со словом "python" в имени или описании, отсортированные по возрасту по убыванию:
```
GET /search?query=python&order_field=Age&order_by=-1&limit=20&offset=0
```

###  Поиск 5 пользователей начиная со смещения 10, отсортированные по ID по возрастанию:
```
GET /search?order_field=Id&order_by=1&limit=5&offset=10
```
